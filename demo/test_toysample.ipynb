{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple IFR example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from ifr import IFR\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifr_model = IFR(scale=2, maxiter=20,zero_mean=True,\n",
    "                trunc=True,rand_pa=False, kp_nb=False,encoder_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Transform tensor([[[ 0.7150, -0.6970, -0.0543, -0.4716],\n",
      "         [ 0.5443,  0.6037, -0.5824,  0.4599],\n",
      "         [ 0.4388,  0.3868,  0.8111, -0.4687],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def do_transform(p0, x):\n",
    "    # p0: [N, 3]\n",
    "    # x: [1, 6], twist-params\n",
    "    g = utils.exp(x).to(p0) # [1, 4, 4]\n",
    "    p1 = utils.transform(g, p0)\n",
    "    igt = g.squeeze(0) # igt: p0 -> p1\n",
    "    return p1, igt\n",
    "\n",
    "\n",
    "# load data\n",
    "p0 = np.load('./p0.npy')\n",
    "p1 = np.load('./p1.npy')\n",
    "\n",
    "# randomly set the twist parameters for the ground truth pose\n",
    "x = np.array([[0.57, -0.29, 0.73, -0.37, 0.48, -0.54]])\n",
    "\n",
    "p1_pre, igt = do_transform(torch.from_numpy(p1[np.newaxis,...]), torch.from_numpy(x)[np.newaxis,...])\n",
    "p1_pre = p1_pre.numpy()[0,:,:]\n",
    "print('GT Transform', igt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape without downsample (103974, 3) (76241, 3)\n",
      "\n",
      "\n",
      " Solved:\n",
      " [[ 0.7021345   0.5471499   0.45566896  0.3461575 ]\n",
      " [-0.70915663  0.5949184   0.37837538 -0.44514206]\n",
      " [-0.06405792 -0.58881193  0.8057283   0.6202873 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Error Matrix:\n",
      " [[ 9.99771315e-01  1.71827249e-02  1.27326961e-02  5.30889790e-02]\n",
      " [-1.71702523e-02  9.99851461e-01 -1.07892063e-03 -1.44913672e-02]\n",
      " [-1.27496393e-02  8.59870553e-04  9.99918866e-01  2.08872309e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('Input Shape without downsample', p0.shape, p1_pre.shape)\n",
    "estimated_pose = ifr_model.register(p0, p1_pre)[0,:,:]\n",
    "print('\\n\\n Solved:\\n',estimated_pose)\n",
    "\n",
    "print('Error Matrix:\\n', estimated_pose@igt.numpy()[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis (visualization is on downsampled for fast draw)\n",
    "p0_hat = (estimated_pose[:3,:3]@p1_pre.T+estimated_pose[:3,(3,)]).T\n",
    "\n",
    "import ipyvolume as ipv\n",
    "\n",
    "def plot(x1,x2):\n",
    "    fig = ipv.figure()\n",
    "    scatter = ipv.scatter(x1[:,0], x1[:,1], x1[:,2],np.array([255,0,0]))\n",
    "    scatter = ipv.scatter(x2[:,0], x2[:,1], x2[:,2],np.array([0,0,255]))\n",
    "    ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8efc4a7da70437ab64606721b917c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), projectionMatrix=(1.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e172a60f0c54943b29f99acc2f48d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), projectionMatrix=(1.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(p0, p1_pre)\n",
    "plot(p0, p0_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
